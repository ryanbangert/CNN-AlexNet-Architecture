# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hu8Hv6FHRo7arREwFG9Iv7aPdc2EpYKy
"""

import tensorflow.keras
from keras.datasets import fashion_mnist
from keras.models import Sequential
from keras import layers
from tensorflow.keras.utils import to_categorical

num_classes=10
(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()
print(train_X.shape)
print(test_X.shape)
img_height, img_width, channel = train_X.shape[1],train_X.shape[2],1

train_X = train_X.reshape(-1, 28, 28, 1) #buradaki 1, 1 kanallı olduğunu belirtir.
test_X = test_X.reshape(-1,28,28,1) #buradaki 1, 1 kanallı olduğunu belirtir.

#normalize eder (0,-1 aralığında değerlere çeker)
train_X = train_X.astype("float32")
test_X = test_X.astype("float32")
train_X = train_X/255
test_X = test_X/255

test_Y_one_hot = to_categorical(test_Y, num_classes=num_classes)
train_Y_one_hot = to_categorical(train_Y, num_classes=num_classes)
# (3) Create a sequential model
model = Sequential()

# 1st Convolutional Layer
model.add(layers.Conv2D(filters=96, input_shape=(img_height, img_width, channel,), kernel_size=(11,11),\
 strides=(4,4), padding='same'))
model.add(layers.Activation('relu'))
# Pooling 
model.add(layers.MaxPooling2D(pool_size=(5,5), strides=(2,2), padding='same'))
# Batch Normalisation before passing it to the next layer
model.add(layers.BatchNormalization())

# 2nd Convolutional Layer
model.add(layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))
model.add(layers.Activation('relu'))
# Pooling
model.add(layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))
# Batch Normalisation
model.add(layers.BatchNormalization())

# 3rd Convolutional Layer
model.add(layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))
model.add(layers.Activation('relu'))
# Batch Normalisation
model.add(layers.BatchNormalization())

# 4th Convolutional Layer
model.add(layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))
model.add(layers.Activation('relu'))
# Batch Normalisation
model.add(layers.BatchNormalization())

# 5th Convolutional Layer
model.add(layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))
model.add(layers.Activation('relu'))
# Pooling
model.add(layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))
# Batch Normalisation
model.add(layers.BatchNormalization())

# Passing it to a dense layer
model.add(layers.Flatten())
# 1st Dense Layer
model.add(layers.Dense(4096, input_shape=(28*28*3,)))
model.add(layers.Activation('relu'))
# Add Dropout to prevent overfitting
model.add(layers.Dropout(0.4))
# Batch Normalisation
model.add(layers.BatchNormalization())

# 2nd Dense Layer
model.add(layers.Dense(512))
model.add(layers.Activation('relu'))
# Add Dropout
model.add(layers.Dropout(0.4))
# Batch Normalisation
model.add(layers.BatchNormalization())

# 3rd Dense Layer
model.add(layers.Dense(256))
model.add(layers.Activation('relu'))
# Add Dropout
model.add(layers.Dropout(0.4))
# Batch Normalisation
model.add(layers.BatchNormalization())

# Output Layer
model.add(layers.Dense(num_classes))
model.add(layers.Activation('softmax'))

model.summary()
print("BAŞLADI")

import tensorflow.keras 

model.compile(loss=tensorflow.keras.losses.categorical_crossentropy, optimizer=tensorflow.keras.optimizers.Adam(), metrics=['accuracy'])
model.fit(train_X, train_Y_one_hot, batch_size=64, epochs=100)
test_loss, test_acc = model.evaluate(test_X, test_Y_one_hot)
print("Test Loss", test_loss)
print("Test Accuracy",test_acc)